{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8658076921685575053\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1968491726\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14262160405642374993\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.device('/gpu:0')\n",
    "print(device_lib.list_local_devices())\n",
    "label_classes = ['森森', '牛排', '巧巧', '小白', '花捲', '黑胖', '乖狗', '橘子', '烏龜', '松鼠', '笨鳥']\n",
    "\n",
    "num_of_class = len(label_classes)\n",
    "batch_size = 32\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1034 images belonging to 11 classes.\n",
      "森森 with 122 images\n",
      "牛排 with 115 images\n",
      "巧巧 with 116 images\n",
      "小白 with 105 images\n",
      "花捲 with  94 images\n",
      "黑胖 with 117 images\n",
      "乖狗 with 148 images\n",
      "橘子 with  99 images\n",
      "烏龜 with  59 images\n",
      "松鼠 with  20 images\n",
      "笨鳥 with  39 images\n",
      "\n",
      "Found 251 images belonging to 11 classes.\n",
      "森森 with  30 images\n",
      "牛排 with  28 images\n",
      "巧巧 with  28 images\n",
      "小白 with  26 images\n",
      "花捲 with  23 images\n",
      "黑胖 with  29 images\n",
      "乖狗 with  36 images\n",
      "橘子 with  24 images\n",
      "烏龜 with  14 images\n",
      "松鼠 with   4 images\n",
      "笨鳥 with   9 images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # rotation_range=10,\n",
    "    # shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "for i, j in Counter(train_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "print()\n",
    "\n",
    "# valid\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "for i, j in Counter(valid_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_batch in train_generator:\n",
    "#     images = my_batch[0]\n",
    "#     labels = my_batch[1]\n",
    "#     for i in range(3):\n",
    "#         print(label_classes[labels[i].argmax()])\n",
    "#         plt.imshow(images[i])\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 11)                14091     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,272,075\n",
      "Trainable params: 14,091\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    include_top = False,\n",
    "    input_shape = target_size + (3, ),\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# base_model.summary()\n",
    "\n",
    "# # fine tune\n",
    "# for layer in base_model.layers:\n",
    "#     if(layer.name in ['Conv_1', 'Conv_2']):\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    # layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    # layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(num_of_class, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "\n",
    "my_callback = [tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights_save/weights_L_{epoch:03d}_{val_accuracy:.2f}.hdf5',\n",
    "    # filepath='weights_save/weights_S_{epoch:03d}_{val_accuracy:.2f}.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    save_weights_only=True,\n",
    "    mode='max'\n",
    ")]\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(filepath='weights_save/weights005_0.72.hdf5')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    epochs=10,\n",
    "    # callbacks=my_callback\n",
    ")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc', linewidth=0.5)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "# 儲存acc學習曲線\n",
    "# plt.savefig('./acc.png')\n",
    "plt.show()\n",
    "# 畫出loss學習曲線\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss', linewidth=0.5)\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "# 儲存loss學習曲線\n",
    "# plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08507218956947327\n",
      "Train accuracy: 0.9817073345184326\n",
      "Validation loss: 0.16960853338241577\n",
      "Validation accuracy: 0.9453125\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.evaluate(train_generator, verbose=0, steps=STEP_SIZE_TRAIN)\n",
    "pred_val = model.evaluate(valid_generator, verbose=0, steps=STEP_SIZE_VALID)\n",
    "\n",
    "print(\"Train loss:\", pred_train[0])\n",
    "print(\"Train accuracy:\", pred_train[1])\n",
    "print(\"Validation loss:\", pred_val[0])\n",
    "print(\"Validation accuracy:\", pred_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='test/',\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    ")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for data, label in test_generator:\n",
    "    \n",
    "    prediction = np.argmax(model.predict(data), axis=1)\n",
    "    predictions.extend(prediction)\n",
    "    \n",
    "    images.extend(data)\n",
    "    \n",
    "    labels.extend(np.argmax(label, axis=1))\n",
    "    \n",
    "    if (len(predictions) == test_generator.n):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for data, label in valid_generator:\n",
    "    \n",
    "    prediction = np.argmax(model.predict(data), axis=1)\n",
    "    predictions.extend(prediction)\n",
    "    \n",
    "    images.extend(data)\n",
    "    \n",
    "    labels.extend(np.argmax(label, axis=1))\n",
    "    \n",
    "    if (len(predictions) == valid_generator.n):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_generator.n):\n",
    "    print(f\"label={label_classes[labels[i]]} | predict={label_classes[predictions[i]]}\")\n",
    "    plt.imshow(images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
      "c:\\Users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpi58y9wfo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpi58y9wfo\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model.tflite\", \"wb\") as fh:\n",
    "    fh.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1d89cca3e8f8885eedf6c172f8c90ab3d060625a63bbfb433ea110391a0eab0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
