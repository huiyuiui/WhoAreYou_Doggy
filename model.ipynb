{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "label_classes = ['森森', '牛排', '巧巧', '小白', '花捲', '金毛', '吊吊', '黑胖', '乖狗', '橘子']\n",
    "\n",
    "num_of_class = len(label_classes)\n",
    "batch_size = 32\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 706 images belonging to 10 classes.\n",
      "森森 with  48 images\n",
      "牛排 with 112 images\n",
      "巧巧 with  54 images\n",
      "小白 with 323 images\n",
      "花捲 with   3 images\n",
      "吊吊 with   5 images\n",
      "黑胖 with 113 images\n",
      "乖狗 with  28 images\n",
      "橘子 with  20 images\n",
      "\n",
      "Found 172 images belonging to 10 classes.\n",
      "森森 with  12 images\n",
      "牛排 with  28 images\n",
      "巧巧 with  13 images\n",
      "小白 with  80 images\n",
      "吊吊 with   1 images\n",
      "黑胖 with  28 images\n",
      "乖狗 with   6 images\n",
      "橘子 with   4 images\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "for i, j in Counter(train_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "print()\n",
    "\n",
    "# valid\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "for i, j in Counter(valid_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_batch in train_generator:\n",
    "#     images = my_batch[0]\n",
    "#     labels = my_batch[1]\n",
    "#     for i in range(3):\n",
    "#         print(label_classes[labels[i].argmax()])\n",
    "#         plt.imshow(images[i])\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3large (Functiona  (None, 7, 7, 960)        2996352   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 128)         1106048   \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,103,690\n",
      "Trainable params: 1,107,338\n",
      "Non-trainable params: 2,996,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV3Large(\n",
    "    include_top = False,\n",
    "    input_shape = target_size + (3, ),\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(num_of_class, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 142s 6s/step - loss: 0.2775 - accuracy: 0.4561 - val_loss: 0.2395 - val_accuracy: 0.6337\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 134s 6s/step - loss: 0.2232 - accuracy: 0.5142 - val_loss: 0.2243 - val_accuracy: 0.3605\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 133s 6s/step - loss: 0.2053 - accuracy: 0.5595 - val_loss: 0.1930 - val_accuracy: 0.6860\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 131s 6s/step - loss: 0.1835 - accuracy: 0.6558 - val_loss: 0.1602 - val_accuracy: 0.6453\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 120s 5s/step - loss: 0.1666 - accuracy: 0.6884 - val_loss: 0.1476 - val_accuracy: 0.7849\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 131s 6s/step - loss: 0.1654 - accuracy: 0.6799 - val_loss: 0.1423 - val_accuracy: 0.7965\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 130s 6s/step - loss: 0.1481 - accuracy: 0.7550 - val_loss: 0.1304 - val_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 130s 6s/step - loss: 0.1451 - accuracy: 0.7167 - val_loss: 0.1268 - val_accuracy: 0.8081\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 132s 6s/step - loss: 0.1421 - accuracy: 0.7493 - val_loss: 0.1274 - val_accuracy: 0.8779\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 129s 6s/step - loss: 0.1275 - accuracy: 0.7762 - val_loss: 0.1310 - val_accuracy: 0.8081\n"
     ]
    }
   ],
   "source": [
    "# my_callback = [tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='model_save/model_{epoch:03d}'\n",
    "# )]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc', linewidth=0.5)\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "# # 儲存acc學習曲線\n",
    "# # plt.savefig('./acc.png')\n",
    "# plt.show()\n",
    "\n",
    "# # 畫出loss學習曲線\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "# plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss', linewidth=0.5)\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.grid()\n",
    "# # 儲存loss學習曲線\n",
    "# # plt.savefig('loss.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1368836760520935\n",
      "Train accuracy: 0.7252124547958374\n",
      "Validation loss: 0.13104094564914703\n",
      "Validation accuracy: 0.8081395626068115\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.evaluate(train_generator, verbose=0)\n",
    "pred_val = model.evaluate(valid_generator, verbose=0)\n",
    "\n",
    "print(\"Train loss:\", pred_train[0])\n",
    "print(\"Train accuracy:\", pred_train[1])\n",
    "print(\"Validation loss:\", pred_val[0])\n",
    "print(\"Validation accuracy:\", pred_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(valid_generator, verbose=0)\n",
    "# prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "# images = valid_generator[0][0]\n",
    "# labels = np.argmax(valid_generator[0][1], axis=1)\n",
    "\n",
    "# for i in range(9):\n",
    "#     print(f\"label={label_classes[labels[i]]} | predict={label_classes[prediction[i]]}\")\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model.tflite\", \"wb\") as fh:\n",
    "    fh.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d666d82339d4ec6598db6520b8ef6e55f52b78af793bca546f20d1c79188d15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
