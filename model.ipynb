{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "tf.device('/gpu:0')\n",
    "print(device_lib.list_local_devices())\n",
    "label_classes = ['森森', '牛排', '巧巧', '小白', '花捲', '黑胖', '乖狗', '橘子', '烏龜', '松鼠', '笨鳥']\n",
    "\n",
    "num_of_class = len(label_classes)\n",
    "batch_size = 32\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # rotation_range=10,\n",
    "    # shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "for i, j in Counter(train_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "print()\n",
    "\n",
    "# valid\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "for i, j in Counter(valid_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "print()\n",
    "    \n",
    "# test\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"test_data/\",\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    ")\n",
    "for i, j in Counter(test_generator.classes).items():\n",
    "    print(f\"{label_classes[i]} with {j:3d} images\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_batch in train_generator:\n",
    "#     images = my_batch[0]\n",
    "#     labels = my_batch[1]\n",
    "#     for i in range(3):\n",
    "#         print(label_classes[labels[i].argmax()])\n",
    "#         plt.imshow(images[i])\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    include_top = False,\n",
    "    input_shape = target_size + (3, ),\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# base_model.summary()\n",
    "\n",
    "# # fine tune\n",
    "# for layer in base_model.layers:\n",
    "#     if(layer.name in ['Conv_1', 'Conv_2']):\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    # layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    # layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(num_of_class, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "\n",
    "my_callback = [tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='weights_save/weights_L_{epoch:03d}_{val_accuracy:.2f}.hdf5',\n",
    "    # filepath='weights_save/weights_S_{epoch:03d}_{val_accuracy:.2f}.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    save_weights_only=True,\n",
    "    mode='max'\n",
    ")]\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    epochs=10,\n",
    "    # callbacks=my_callback\n",
    ")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc', linewidth=0.5)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "# 儲存acc學習曲線\n",
    "# plt.savefig('./acc.png')\n",
    "plt.show()\n",
    "# 畫出loss學習曲線\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss', linewidth=0.5)\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "# 儲存loss學習曲線\n",
    "# plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08507218956947327\n",
      "Train accuracy: 0.9817073345184326\n",
      "Validation loss: 0.16960853338241577\n",
      "Validation accuracy: 0.9453125\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.evaluate(train_generator, verbose=0, steps=STEP_SIZE_TRAIN)\n",
    "pred_val = model.evaluate(valid_generator, verbose=0, steps=STEP_SIZE_VALID)\n",
    "\n",
    "print(\"Train loss:\", pred_train[0])\n",
    "print(\"Train accuracy:\", pred_train[1])\n",
    "print(\"Validation loss:\", pred_val[0])\n",
    "print(\"Validation accuracy:\", pred_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='test/',\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    classes=label_classes,\n",
    ")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for data, label in test_generator:\n",
    "    \n",
    "    prediction = np.argmax(model.predict(data), axis=1)\n",
    "    predictions.extend(prediction)\n",
    "    \n",
    "    images.extend(data)\n",
    "    \n",
    "    labels.extend(np.argmax(label, axis=1))\n",
    "    \n",
    "    if (len(predictions) == test_generator.n):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "for data, label in valid_generator:\n",
    "    \n",
    "    prediction = np.argmax(model.predict(data), axis=1)\n",
    "    predictions.extend(prediction)\n",
    "    \n",
    "    images.extend(data)\n",
    "    \n",
    "    labels.extend(np.argmax(label, axis=1))\n",
    "    \n",
    "    if (len(predictions) == valid_generator.n):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9, 18):\n",
    "    print(f\"label={label_classes[labels[i]]} | predict={label_classes[predictions[i]]}\")\n",
    "    plt.imshow(images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
      "c:\\Users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpi58y9wfo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpi58y9wfo\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model.tflite\", \"wb\") as fh:\n",
    "    fh.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1d89cca3e8f8885eedf6c172f8c90ab3d060625a63bbfb433ea110391a0eab0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
